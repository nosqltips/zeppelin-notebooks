{
  "paragraphs": [
    {
      "text": "%md\n## We create a Spark streaming context and the use that to create the twitter stream.\n### The streaming context essentially creates small batches based on a time value, 5 seconds in this case.\n### Each batch is and RDD that you can use like any other RDD, though it does have some special properties.",
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447984858789_-1741566349",
      "id": "20151119-190058_1533857509",
      "dateCreated": "Nov 19, 2015 7:00:58 PM",
      "dateStarted": "Nov 28, 2015 1:12:00 PM",
      "dateFinished": "Nov 28, 2015 1:12:00 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.SparkContext._\nimport org.apache.spark.streaming.twitter._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.streaming.{Time, Seconds, StreamingContext}\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.sql.SQLContext\n\n// Set the system properties so that Twitter4j library used by twitter stream\n// can use them to generat OAuth credentials\nSystem.setProperty(\"twitter4j.oauth.consumerKey\", \"\")\nSystem.setProperty(\"twitter4j.oauth.consumerSecret\", \"\")\nSystem.setProperty(\"twitter4j.oauth.accessToken\", \"\")\nSystem.setProperty(\"twitter4j.oauth.accessTokenSecret\", \"\")\n\nval filters \u003d Array(\"Big Data\", \"Spark\", \"Hadoop\", \"#bigmoutaindata\")\n\n// Start up the streaming pipeline\nval ssc \u003d new StreamingContext(sc, Seconds(5))\nval stream \u003d TwitterUtils.createStream(ssc, None, filters)\n",
      "dateUpdated": "Dec 16, 2015 12:49:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "lineNumbers": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447980791957_-1453825601",
      "id": "20151119-175311_1798108412",
      "dateCreated": "Nov 19, 2015 5:53:11 PM",
      "dateStarted": "Nov 28, 2015 6:35:45 PM",
      "dateFinished": "Nov 28, 2015 6:36:26 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Pull all of the #hashtags from each twitter message.\n### This is done with a filter that simply looks for things that start with a # symbol.\n### We create a new RDD that counts all of the occurances of a tag, then sorts by count.",
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447985176664_35603024",
      "id": "20151119-190616_1687950378",
      "dateCreated": "Nov 19, 2015 7:06:16 PM",
      "dateStarted": "Nov 28, 2015 1:12:00 PM",
      "dateFinished": "Nov 28, 2015 1:12:00 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n    val hashTags \u003d stream.flatMap(status \u003d\u003e status.getText.split(\" \").filter(_.startsWith(\"#\")))\n\n    val topCounts \u003d hashTags\n                    .map((_, 1))\n                    .reduceByKeyAndWindow(_ + _, Seconds(300))\n                    .map{case (topic, count) \u003d\u003e (count, topic)}\n                    .transform(_.sortByKey(false))\n",
      "dateUpdated": "Nov 28, 2015 6:36:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": false,
        "lineNumbers": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447985117374_-1424008420",
      "id": "20151119-190517_1138223728",
      "dateCreated": "Nov 19, 2015 7:05:17 PM",
      "dateStarted": "Nov 28, 2015 6:36:43 PM",
      "dateFinished": "Nov 28, 2015 6:36:45 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Convert the RDD into a DataFrame that we can use for querying.\n### We use a case class to act as a model for the DataFrame.\n### The data in the RDD, which is a map now, is used to create DataFrames that we can query against.",
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447996945885_1931403927",
      "id": "20151119-222225_565954034",
      "dateCreated": "Nov 19, 2015 10:22:25 PM",
      "dateStarted": "Nov 28, 2015 1:12:00 PM",
      "dateFinished": "Nov 28, 2015 1:12:00 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n    /** Case class for converting RDD to DataFrame */\n    case class Record(count: Int, topic: String)\n\n    // Print popular hashtags\n    topCounts.foreachRDD(rdd \u003d\u003e {\n\n    // Convert RDD[String] to RDD[case class] to DataFrame\n//    val df \u003d rdd.map(p \u003d\u003e Record(p._1, p._2)).toDF()\n    val df \u003d rdd.map{case (k, v) \u003d\u003e Record(k, v)}.toDF()\n\n    // Register as table\n    df.registerTempTable(\"topCounts\")\n})\n",
      "dateUpdated": "Nov 28, 2015 6:36:46 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "lineNumbers": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447985207413_1522688172",
      "id": "20151119-190647_175888297",
      "dateCreated": "Nov 19, 2015 7:06:47 PM",
      "dateStarted": "Nov 28, 2015 6:36:46 PM",
      "dateFinished": "Nov 28, 2015 6:36:47 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Start the streaming context, which actually starts pulling in data from twitter.\n### All of the previous commands only set up pipeline, but nothing was actually processed until this line.",
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447996878375_1363606496",
      "id": "20151119-222118_1067994868",
      "dateCreated": "Nov 19, 2015 10:21:18 PM",
      "dateStarted": "Nov 28, 2015 1:12:00 PM",
      "dateFinished": "Nov 28, 2015 1:12:00 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n ssc.start()",
      "dateUpdated": "Nov 28, 2015 6:36:52 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "lineNumbers": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447985277485_353359643",
      "id": "20151119-190757_1852564573",
      "dateCreated": "Nov 19, 2015 7:07:57 PM",
      "dateStarted": "Nov 28, 2015 6:36:52 PM",
      "dateFinished": "Nov 28, 2015 6:36:53 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Create a SQL query so we can view the data that is coming in from twitter.",
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447997425449_-1159394546",
      "id": "20151119-223025_1233384509",
      "dateCreated": "Nov 19, 2015 10:30:25 PM",
      "dateStarted": "Nov 28, 2015 1:12:00 PM",
      "dateFinished": "Nov 28, 2015 1:12:00 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nselect * from topCounts",
      "dateUpdated": "Nov 28, 2015 9:00:54 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "pieChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "topic",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "yAxis": {
              "name": "count",
              "index": 0.0,
              "aggr": "sum"
            },
            "size": {
              "name": "count",
              "index": 0.0,
              "aggr": "sum"
            },
            "xAxis": {
              "name": "topic",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447985343275_-100736004",
      "id": "20151119-190903_1222943819",
      "dateCreated": "Nov 19, 2015 7:09:03 PM",
      "dateStarted": "Nov 28, 2015 9:00:54 PM",
      "dateFinished": "Nov 28, 2015 9:00:54 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n# ssc.stop()",
      "dateUpdated": "Nov 28, 2015 1:06:25 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "lineNumbers": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447992675084_-432022602",
      "id": "20151119-211115_488475851",
      "dateCreated": "Nov 19, 2015 9:11:15 PM",
      "dateStarted": "Nov 28, 2015 1:12:06 PM",
      "dateFinished": "Nov 28, 2015 1:12:06 PM",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Nov 28, 2015 1:04:19 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447993542784_-868131406",
      "id": "20151119-212542_966328226",
      "dateCreated": "Nov 19, 2015 9:25:42 PM",
      "dateStarted": "Nov 28, 2015 1:12:06 PM",
      "dateFinished": "Nov 28, 2015 1:12:06 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Twitter Streaming",
  "id": "2B51BGS3N",
  "angularObjects": {
    "2B66ZUTPN": [],
    "2B3FA4R9D": [],
    "2B3AMXAM9": [],
    "2B65G5377": [],
    "2B2Z8V4VJ": [],
    "2B612PC5W": [],
    "2B3WG8PW2": [],
    "2B56BDHCF": [],
    "2B6U8N5CW": [],
    "2B55D32UY": [],
    "2B3HGSH5R": [],
    "2B2XYY1VE": [],
    "2B526C332": []
  },
  "config": {
    "looknfeel": "default",
    "cron": ""
  },
  "info": {}
}